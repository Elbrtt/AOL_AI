{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd08d958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FOOD WASTE PREDICTION MODEL - RETAIL OPTIMIZATION\n",
      "============================================================\n",
      "\n",
      "ğŸ“Š Generating sample data...\n",
      "\n",
      "âœ… Generated 2000 samples\n",
      "\n",
      "ğŸ“‹ Sample Data Preview:\n",
      "     category        event_type  shelf_life_days  stock_ordered  avg_daily_sales  price_per_unit_k  days_before_event  event_duration  needs_refrigeration  supplier_reliability  store_size  expected_sales  waste_units  waste_value_k  waste_percentage\n",
      "0      Bakery            Normal                5            429               37             27.10                 10               7                    0                 0.910           2             259           77        2086.91             17.95\n",
      "1  Vegetables  Natal_Tahun_Baru                8            997               25             97.45                  7               9                    0                 0.966           2             448          109       10621.61             10.93\n",
      "2     Seafood            Normal                4            393               31             55.74                  4               7                    1                 0.997           3             217           87        4849.67             22.14\n",
      "3  Vegetables      Long_Weekend               10            539               43             75.97                  7               4                    0                 0.999           1             209          148       11243.01             27.46\n",
      "4      Snacks           Ramadan              130            123               53             15.60                  7              30                    0                 0.963           2            2185            0           0.00              0.00\n",
      "5     Seafood     Mudik_Lebaran                2            363               17             27.88                 10              10                    1                 0.945           3              90          243        6775.52             66.94\n",
      "6      Snacks     Mudik_Lebaran              143            917               12             60.89                  4              14                    0                 0.912           1              61          205       12482.31             22.36\n",
      "7     Seafood           Ramadan                5            280               16             68.97                 11              30                    1                 0.802           1             765            0           0.00              0.00\n",
      "8      Bakery      Long_Weekend                7            671               61             90.73                  3               4                    0                 0.978           2             364            8         725.86              1.19\n",
      "9     Seafood  Natal_Tahun_Baru                2            779               20             85.88                  2               7                    1                 0.821           3             268          295       25333.87             37.87\n",
      "\n",
      "ğŸ“ˆ Data Statistics:\n",
      "       shelf_life_days  stock_ordered  avg_daily_sales  price_per_unit_k  days_before_event  event_duration  needs_refrigeration  supplier_reliability  store_size  expected_sales  waste_units  waste_value_k  waste_percentage\n",
      "count      2000.000000    2000.000000      2000.000000       2000.000000        2000.000000     2000.000000          2000.000000           2000.000000  2000.00000     2000.000000  2000.000000    2000.000000       2000.000000\n",
      "mean         27.861500     521.593500        44.573000         52.806000           7.431500       11.945500             0.370500              0.853714     2.04000      704.114000    85.557000    4520.828685         11.440475\n",
      "std          40.671629     312.959151        20.895071         27.381417           3.975073        8.505628             0.483059              0.086316     0.80977      837.150581   170.487433   10681.524087         18.096571\n",
      "min           2.000000      53.000000        10.000000          5.120000           1.000000        3.000000             0.000000              0.700000     1.00000       37.000000     0.000000       0.000000          0.000000\n",
      "25%           5.000000     270.750000        27.000000         29.685000           4.000000        7.000000             0.000000              0.778000     1.00000      210.000000     0.000000       0.000000          0.000000\n",
      "50%           8.000000     463.000000        44.500000         53.040000           7.000000        9.000000             0.000000              0.854000     2.00000      368.000000     0.000000       0.000000          0.000000\n",
      "75%          31.000000     729.000000        62.000000         76.727500          11.000000       14.000000             1.000000              0.930000     3.00000      801.500000    91.000000    3957.777500         18.432500\n",
      "max         179.000000    1693.000000        80.000000         99.960000          14.000000       30.000000             1.000000              1.000000     3.00000     4425.000000  1181.000000  112098.110000         95.220000\n",
      "\n",
      "ğŸ·ï¸ Waste by Event Type:\n",
      "event_type\n",
      "Mudik_Lebaran       33.369017\n",
      "Long_Weekend        10.585244\n",
      "Natal_Tahun_Baru     6.097895\n",
      "Normal               5.363290\n",
      "Ramadan              0.621415\n",
      "\n",
      "ğŸ Waste by Category:\n",
      "category\n",
      "Seafood       17.236969\n",
      "Meat          16.065569\n",
      "Bakery        13.125309\n",
      "Vegetables    12.968441\n",
      "Fruits        11.813102\n",
      "Dairy         11.400124\n",
      "Beverages      4.790526\n",
      "Snacks         4.275041\n",
      "\n",
      "============================================================\n",
      "DATA PREPROCESSING\n",
      "============================================================\n",
      "\n",
      "âœ… Training samples: 1600\n",
      "âœ… Testing samples: 400\n",
      "âœ… Number of features: 12\n",
      "\n",
      "============================================================\n",
      "BUILDING KERAS MODEL\n",
      "============================================================\n",
      "\n",
      "ğŸ“ Model Architecture:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aurelius\\Documents\\GitHub\\AOL_AI\\.venv\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,664</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_1           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_2           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚         \u001b[38;5;34m1,664\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚           \u001b[38;5;34m512\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚         \u001b[38;5;34m8,256\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_1           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             â”‚         \u001b[38;5;34m2,080\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_2           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             â”‚           \u001b[38;5;34m128\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             â”‚           \u001b[38;5;34m528\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚            \u001b[38;5;34m17\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,441</span> (52.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,441\u001b[0m (52.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,993</span> (50.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,993\u001b[0m (50.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING MODEL\n",
      "============================================================\n",
      "Epoch 1/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 451.4025 - mae: 11.7014 - val_loss: 389.5730 - val_mae: 10.5379 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 385.3735 - mae: 10.8413 - val_loss: 356.7790 - val_mae: 10.1130 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 281.6373 - mae: 9.4190 - val_loss: 278.4244 - val_mae: 8.9854 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 172.4035 - mae: 7.6376 - val_loss: 187.0140 - val_mae: 7.4030 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 119.0829 - mae: 6.4326 - val_loss: 133.9871 - val_mae: 6.1947 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 99.4007 - mae: 5.9708 - val_loss: 113.9047 - val_mae: 5.5684 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 100.6300 - mae: 5.9227 - val_loss: 95.0087 - val_mae: 5.1833 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 94.3368 - mae: 5.7267 - val_loss: 90.0747 - val_mae: 5.1861 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 93.1646 - mae: 5.5853 - val_loss: 74.5831 - val_mae: 4.8815 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 86.3322 - mae: 5.3264 - val_loss: 72.3669 - val_mae: 4.7438 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 96.0600 - mae: 5.4998 - val_loss: 71.0723 - val_mae: 4.6739 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 91.2570 - mae: 5.3418 - val_loss: 66.7148 - val_mae: 4.4803 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 79.0158 - mae: 5.0361 - val_loss: 64.8527 - val_mae: 4.4760 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 78.3091 - mae: 5.0118 - val_loss: 61.7748 - val_mae: 4.4280 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 78.0966 - mae: 5.0033 - val_loss: 60.6322 - val_mae: 4.2995 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 76.1017 - mae: 4.9575 - val_loss: 58.2843 - val_mae: 4.2835 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 83.7571 - mae: 5.1250 - val_loss: 55.8411 - val_mae: 4.1687 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 77.2701 - mae: 4.9887 - val_loss: 53.4093 - val_mae: 4.0928 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 67.4881 - mae: 4.6068 - val_loss: 55.9898 - val_mae: 4.1361 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 79.9977 - mae: 4.9761 - val_loss: 57.3258 - val_mae: 4.1886 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.1568 - mae: 4.6186 - val_loss: 53.2219 - val_mae: 4.0871 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 72.4022 - mae: 4.7538 - val_loss: 56.9655 - val_mae: 4.1431 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 64.8294 - mae: 4.4113 - val_loss: 54.4716 - val_mae: 4.0913 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 62.6342 - mae: 4.4743 - val_loss: 51.3491 - val_mae: 4.0216 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 62.6569 - mae: 4.4893 - val_loss: 54.3620 - val_mae: 4.2364 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 72.6085 - mae: 4.7232 - val_loss: 53.1300 - val_mae: 4.1235 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 57.3390 - mae: 4.2378 - val_loss: 50.9918 - val_mae: 4.0062 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 68.5901 - mae: 4.6101 - val_loss: 53.2822 - val_mae: 4.0434 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.9975 - mae: 4.6014 - val_loss: 51.2082 - val_mae: 4.0205 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 70.9124 - mae: 4.6530 - val_loss: 52.3362 - val_mae: 4.1232 - learning_rate: 0.0010\n",
      "Epoch 31/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 69.4583 - mae: 4.6943 - val_loss: 52.4450 - val_mae: 4.0455 - learning_rate: 0.0010\n",
      "Epoch 32/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 58.6154 - mae: 4.2772 - val_loss: 50.4875 - val_mae: 4.0263 - learning_rate: 0.0010\n",
      "Epoch 33/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 63.4390 - mae: 4.5035 - val_loss: 53.2253 - val_mae: 4.1116 - learning_rate: 0.0010\n",
      "Epoch 34/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 66.0351 - mae: 4.6399 - val_loss: 51.6299 - val_mae: 4.0236 - learning_rate: 0.0010\n",
      "Epoch 35/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 69.3032 - mae: 4.7024 - val_loss: 50.4102 - val_mae: 3.9980 - learning_rate: 0.0010\n",
      "Epoch 36/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 64.2933 - mae: 4.5277 - val_loss: 49.6903 - val_mae: 3.9718 - learning_rate: 0.0010\n",
      "Epoch 37/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.1309 - mae: 4.5120 - val_loss: 51.1565 - val_mae: 4.0727 - learning_rate: 0.0010\n",
      "Epoch 38/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.7054 - mae: 4.5567 - val_loss: 49.7574 - val_mae: 3.9240 - learning_rate: 0.0010\n",
      "Epoch 39/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 62.6279 - mae: 4.4796 - val_loss: 50.8171 - val_mae: 4.0621 - learning_rate: 0.0010\n",
      "Epoch 40/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 59.1708 - mae: 4.3371 - val_loss: 51.8534 - val_mae: 4.0120 - learning_rate: 0.0010\n",
      "Epoch 41/100\n",
      "\u001b[1m38/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 48.6005 - mae: 4.0093 \n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 52.0917 - mae: 4.0670 - val_loss: 50.4896 - val_mae: 3.9501 - learning_rate: 0.0010\n",
      "Epoch 42/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 62.5247 - mae: 4.3975 - val_loss: 49.0743 - val_mae: 3.9423 - learning_rate: 5.0000e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 54.3841 - mae: 4.0966 - val_loss: 49.2070 - val_mae: 3.8941 - learning_rate: 5.0000e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 57.3206 - mae: 4.2267 - val_loss: 50.6609 - val_mae: 3.9317 - learning_rate: 5.0000e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 51.2593 - mae: 4.0914 - val_loss: 51.2319 - val_mae: 4.0324 - learning_rate: 5.0000e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 52.4736 - mae: 4.0450 - val_loss: 50.5109 - val_mae: 3.9474 - learning_rate: 5.0000e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m31/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53.4347 - mae: 4.1263 \n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 55.3151 - mae: 4.2219 - val_loss: 50.9785 - val_mae: 3.9855 - learning_rate: 5.0000e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 60.1900 - mae: 4.4579 - val_loss: 50.3880 - val_mae: 3.9729 - learning_rate: 2.5000e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 53.0574 - mae: 4.0957 - val_loss: 50.2957 - val_mae: 3.9645 - learning_rate: 2.5000e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 54.5578 - mae: 4.1686 - val_loss: 50.9189 - val_mae: 3.9826 - learning_rate: 2.5000e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 50.3584 - mae: 4.1204 - val_loss: 50.6305 - val_mae: 3.9794 - learning_rate: 2.5000e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m30/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 62.8582 - mae: 4.4554 \n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 63.0113 - mae: 4.5037 - val_loss: 50.5448 - val_mae: 3.9650 - learning_rate: 2.5000e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 67.7984 - mae: 4.5606 - val_loss: 49.9168 - val_mae: 3.9538 - learning_rate: 1.2500e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 51.9636 - mae: 4.1549 - val_loss: 49.9811 - val_mae: 3.9751 - learning_rate: 1.2500e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 55.9071 - mae: 4.2417 - val_loss: 50.0551 - val_mae: 3.9599 - learning_rate: 1.2500e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m40/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 49.2450 - mae: 4.0348 - val_loss: 49.2613 - val_mae: 3.9394 - learning_rate: 1.2500e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m32/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 49.9139 - mae: 4.0262 \n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "\u001b[1m40/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 51.5515 - mae: 4.1292 - val_loss: 49.9853 - val_mae: 3.9705 - learning_rate: 1.2500e-04\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "\n",
      "============================================================\n",
      "MODEL EVALUATION\n",
      "============================================================\n",
      "\u001b[1m13/13\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\n",
      "ğŸ“Š Model Performance Metrics:\n",
      "   â€¢ Mean Absolute Error (MAE): 3.66%\n",
      "   â€¢ Root Mean Squared Error (RMSE): 6.50%\n",
      "   â€¢ RÂ² Score: 0.8728\n",
      "\n",
      "============================================================\n",
      "PREDICTION EXAMPLES - SCENARIO ANALYSIS\n",
      "============================================================\n",
      "\n",
      "ğŸ¯ SKENARIO 1: Stok Susu saat Mudik Lebaran\n",
      "--------------------------------------------------\n",
      "   Kategori: Dairy (Susu)\n",
      "   Event: Mudik Lebaran (12 hari)\n",
      "   Stok dipesan: 300 unit\n",
      "   Shelf life: 14 hari\n",
      "   Expected sales: 150 unit\n",
      "   ğŸ’¡ Prediksi Waste: 26.58%\n",
      "   ğŸ’° Potensi kerugian: Rp 1196K\n",
      "\n",
      "ğŸ¯ SKENARIO 2: Stok Roti saat Natal\n",
      "--------------------------------------------------\n",
      "   Kategori: Bakery (Roti)\n",
      "   Event: Natal & Tahun Baru (8 hari)\n",
      "   Stok dipesan: 200 unit\n",
      "   Shelf life: 5 hari\n",
      "   Expected sales: 400 unit\n",
      "   ğŸ’¡ Prediksi Waste: 0.30%\n",
      "   ğŸ’° Potensi kerugian: Rp 15K\n",
      "\n",
      "ğŸ¯ SKENARIO 3: Stok Snack Hari Biasa\n",
      "--------------------------------------------------\n",
      "   Kategori: Snacks\n",
      "   Event: Normal (7 hari)\n",
      "   Stok dipesan: 100 unit\n",
      "   Shelf life: 120 hari\n",
      "   Expected sales: 105 unit\n",
      "   ğŸ’¡ Prediksi Waste: 0.71%\n",
      "   ğŸ’° Potensi kerugian: Rp 7K\n",
      "\n",
      "============================================================\n",
      "STOCK RECOMMENDATION SYSTEM\n",
      "============================================================\n",
      "\n",
      "ğŸ“¦ REKOMENDASI STOK: Toko Retail saat Mudik Lebaran\n",
      "--------------------------------------------------\n",
      "\n",
      "Kategori     Exp. Sales   Optimal Stock   Safety Buffer  \n",
      "------------------------------------------------------\n",
      "Dairy        180          180                0.0%\n",
      "Bakery       150          150                0.0%\n",
      "Meat         120          120                0.0%\n",
      "Snacks       240          270               12.5%\n",
      "Beverages    300          390               30.0%\n",
      "\n",
      "============================================================\n",
      "SUMMARY & BUSINESS INSIGHTS\n",
      "============================================================\n",
      "\n",
      "ğŸ“Š KEY FINDINGS:\n",
      "\n",
      "1. MUDIK LEBARAN adalah periode dengan waste tertinggi karena:\n",
      "   - Banyak konsumen pulang kampung\n",
      "   - Toko cenderung over-stock mengantisipasi lebaran\n",
      "   - Produk dairy & meat paling berisiko\n",
      "\n",
      "2. FAKTOR UTAMA PENYEBAB WASTE:\n",
      "   - Shelf life pendek + event duration panjang\n",
      "   - Over-ordering saat event besar\n",
      "   - Produk yang butuh refrigerasi\n",
      "\n",
      "3. REKOMENDASI UNTUK RETAIL:\n",
      "   âœ… Kurangi stok produk perishable 30-40% saat mudik\n",
      "   âœ… Fokus pada produk dengan shelf life > 30 hari\n",
      "   âœ… Tingkatkan stok produk tahan lama (snacks, beverages)\n",
      "   âœ… Koordinasi dengan supplier untuk delivery lebih sering\n",
      "   âœ… Implementasi dynamic pricing menjelang kadaluarsa\n",
      "\n",
      "4. POTENSI PENGHEMATAN:\n",
      "   Dengan prediksi akurat, retail dapat mengurangi food waste\n",
      "   hingga 20-35% dan menghemat kerugian signifikan.\n",
      "\n",
      "\n",
      "âœ… Model berhasil dibuat dan siap digunakan untuk prediksi!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Food Waste Prediction Model untuk Retail\n",
    "Memprediksi waste akibat stok kadaluarsa saat event besar (Mudik, Lebaran, Natal, dll)\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "\n",
    "# Set random seed untuk reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# ============================================\n",
    "# 1. GENERATE SAMPLE DATA\n",
    "# ============================================\n",
    "\n",
    "def generate_sample_data(n_samples=2000):\n",
    "    \"\"\"\n",
    "    Generate sample data untuk training model prediksi food waste\n",
    "    \"\"\"\n",
    "    \n",
    "    # Kategori produk makanan\n",
    "    categories = ['Dairy', 'Bakery', 'Meat', 'Seafood', 'Fruits', 'Vegetables', 'Snacks', 'Beverages']\n",
    "    \n",
    "    # Event types\n",
    "    events = ['Normal', 'Mudik_Lebaran', 'Natal_Tahun_Baru', 'Long_Weekend', 'Ramadan']\n",
    "    \n",
    "    # Generate data\n",
    "    data = []\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        # Basic features\n",
    "        category = random.choice(categories)\n",
    "        event_type = random.choice(events)\n",
    "        \n",
    "        # Shelf life berdasarkan kategori (dalam hari)\n",
    "        shelf_life_map = {\n",
    "            'Dairy': random.randint(7, 21),\n",
    "            'Bakery': random.randint(3, 7),\n",
    "            'Meat': random.randint(3, 7),\n",
    "            'Seafood': random.randint(2, 5),\n",
    "            'Fruits': random.randint(5, 14),\n",
    "            'Vegetables': random.randint(5, 10),\n",
    "            'Snacks': random.randint(60, 180),\n",
    "            'Beverages': random.randint(30, 90)\n",
    "        }\n",
    "        shelf_life = shelf_life_map[category]\n",
    "        \n",
    "        # Stock ordered (dalam unit)\n",
    "        base_stock = random.randint(50, 500)\n",
    "        \n",
    "        # Event multiplier untuk stok\n",
    "        event_stock_multiplier = {\n",
    "            'Normal': 1.0,\n",
    "            'Mudik_Lebaran': random.uniform(2.0, 3.5),\n",
    "            'Natal_Tahun_Baru': random.uniform(1.8, 2.8),\n",
    "            'Long_Weekend': random.uniform(1.3, 1.8),\n",
    "            'Ramadan': random.uniform(1.5, 2.5)\n",
    "        }\n",
    "        stock_ordered = int(base_stock * event_stock_multiplier[event_type])\n",
    "        \n",
    "        # Historical average daily sales\n",
    "        avg_daily_sales = random.randint(10, 80)\n",
    "        \n",
    "        # Price per unit (dalam ribuan rupiah)\n",
    "        price_per_unit = random.uniform(5, 100)\n",
    "        \n",
    "        # Days before event (kapan stok dipesan sebelum event)\n",
    "        days_before_event = random.randint(1, 14)\n",
    "        \n",
    "        # Event duration (dalam hari)\n",
    "        event_duration = {\n",
    "            'Normal': 7,\n",
    "            'Mudik_Lebaran': random.randint(10, 14),\n",
    "            'Natal_Tahun_Baru': random.randint(7, 10),\n",
    "            'Long_Weekend': random.randint(3, 5),\n",
    "            'Ramadan': random.randint(25, 30)\n",
    "        }[event_type]\n",
    "        \n",
    "        # Temperature storage requirement (1=refrigerated, 0=room temp)\n",
    "        needs_refrigeration = 1 if category in ['Dairy', 'Meat', 'Seafood'] else 0\n",
    "        \n",
    "        # Supplier reliability score (0-1)\n",
    "        supplier_reliability = random.uniform(0.7, 1.0)\n",
    "        \n",
    "        # Store size (1=small, 2=medium, 3=large)\n",
    "        store_size = random.randint(1, 3)\n",
    "        \n",
    "        # Calculate expected sales during event\n",
    "        event_sales_boost = {\n",
    "            'Normal': 1.0,\n",
    "            'Mudik_Lebaran': random.uniform(0.3, 0.6),  # Banyak orang mudik, sales turun\n",
    "            'Natal_Tahun_Baru': random.uniform(1.5, 2.2),\n",
    "            'Long_Weekend': random.uniform(1.2, 1.6),\n",
    "            'Ramadan': random.uniform(1.3, 2.0)\n",
    "        }[event_type]\n",
    "        \n",
    "        expected_sales = int(avg_daily_sales * event_duration * event_sales_boost)\n",
    "        \n",
    "        # Calculate waste (target variable)\n",
    "        # Waste terjadi jika stok > expected sales DAN shelf_life < days_before_event + event_duration\n",
    "        \n",
    "        potential_excess = max(0, stock_ordered - expected_sales)\n",
    "        \n",
    "        # Faktor yang mempengaruhi waste\n",
    "        waste_probability = 0.0\n",
    "        \n",
    "        # Shelf life pendek = waste lebih tinggi\n",
    "        if shelf_life < (days_before_event + event_duration):\n",
    "            waste_probability += 0.4\n",
    "        \n",
    "        # Event Mudik = banyak waste karena orang pulang kampung\n",
    "        if event_type == 'Mudik_Lebaran':\n",
    "            waste_probability += 0.3\n",
    "            \n",
    "        # Produk yang butuh refrigerasi lebih rentan\n",
    "        if needs_refrigeration:\n",
    "            waste_probability += 0.15\n",
    "            \n",
    "        # Supplier tidak reliable\n",
    "        if supplier_reliability < 0.85:\n",
    "            waste_probability += 0.1\n",
    "            \n",
    "        # Random noise\n",
    "        waste_probability += random.uniform(-0.1, 0.1)\n",
    "        waste_probability = max(0, min(1, waste_probability))\n",
    "        \n",
    "        # Calculate actual waste\n",
    "        waste_units = int(potential_excess * waste_probability * random.uniform(0.5, 1.2))\n",
    "        waste_units = max(0, waste_units)\n",
    "        \n",
    "        # Waste value (kerugian dalam ribuan rupiah)\n",
    "        waste_value = waste_units * price_per_unit\n",
    "        \n",
    "        # Waste percentage\n",
    "        waste_percentage = (waste_units / stock_ordered * 100) if stock_ordered > 0 else 0\n",
    "        \n",
    "        data.append({\n",
    "            'category': category,\n",
    "            'event_type': event_type,\n",
    "            'shelf_life_days': shelf_life,\n",
    "            'stock_ordered': stock_ordered,\n",
    "            'avg_daily_sales': avg_daily_sales,\n",
    "            'price_per_unit_k': round(price_per_unit, 2),\n",
    "            'days_before_event': days_before_event,\n",
    "            'event_duration': event_duration,\n",
    "            'needs_refrigeration': needs_refrigeration,\n",
    "            'supplier_reliability': round(supplier_reliability, 3),\n",
    "            'store_size': store_size,\n",
    "            'expected_sales': expected_sales,\n",
    "            'waste_units': waste_units,\n",
    "            'waste_value_k': round(waste_value, 2),\n",
    "            'waste_percentage': round(waste_percentage, 2)\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Generate data\n",
    "print(\"=\" * 60)\n",
    "print(\"FOOD WASTE PREDICTION MODEL - RETAIL OPTIMIZATION\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nğŸ“Š Generating sample data...\")\n",
    "df = generate_sample_data(2000)\n",
    "\n",
    "print(f\"\\nâœ… Generated {len(df)} samples\")\n",
    "print(\"\\nğŸ“‹ Sample Data Preview:\")\n",
    "print(df.head(10).to_string())\n",
    "\n",
    "print(\"\\nğŸ“ˆ Data Statistics:\")\n",
    "print(df.describe().to_string())\n",
    "\n",
    "print(\"\\nğŸ·ï¸ Waste by Event Type:\")\n",
    "print(df.groupby('event_type')['waste_percentage'].mean().sort_values(ascending=False).to_string())\n",
    "\n",
    "print(\"\\nğŸ Waste by Category:\")\n",
    "print(df.groupby('category')['waste_percentage'].mean().sort_values(ascending=False).to_string())\n",
    "\n",
    "# ============================================\n",
    "# 2. DATA PREPROCESSING\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DATA PREPROCESSING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Encode categorical variables\n",
    "le_category = LabelEncoder()\n",
    "le_event = LabelEncoder()\n",
    "\n",
    "df['category_encoded'] = le_category.fit_transform(df['category'])\n",
    "df['event_type_encoded'] = le_event.fit_transform(df['event_type'])\n",
    "\n",
    "# Features untuk model\n",
    "feature_columns = [\n",
    "    'category_encoded',\n",
    "    'event_type_encoded', \n",
    "    'shelf_life_days',\n",
    "    'stock_ordered',\n",
    "    'avg_daily_sales',\n",
    "    'price_per_unit_k',\n",
    "    'days_before_event',\n",
    "    'event_duration',\n",
    "    'needs_refrigeration',\n",
    "    'supplier_reliability',\n",
    "    'store_size',\n",
    "    'expected_sales'\n",
    "]\n",
    "\n",
    "X = df[feature_columns].values\n",
    "y = df['waste_percentage'].values  # Prediksi waste percentage\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"\\nâœ… Training samples: {len(X_train)}\")\n",
    "print(f\"âœ… Testing samples: {len(X_test)}\")\n",
    "print(f\"âœ… Number of features: {X.shape[1]}\")\n",
    "\n",
    "# ============================================\n",
    "# 3. BUILD KERAS MODEL\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"BUILDING KERAS MODEL\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Build model\n",
    "model = Sequential([\n",
    "    # Input layer\n",
    "    Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    # Hidden layers\n",
    "    Dense(64, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Dense(32, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Dense(16, activation='relu'),\n",
    "    \n",
    "    # Output layer (regression - prediksi waste percentage)\n",
    "    Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='mse',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "print(\"\\nğŸ“ Model Architecture:\")\n",
    "model.summary()\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=15,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=0.0001,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ============================================\n",
    "# 4. TRAIN MODEL\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TRAINING MODEL\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ============================================\n",
    "# 5. EVALUATE MODEL\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MODEL EVALUATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test_scaled).flatten()\n",
    "\n",
    "# Metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\nğŸ“Š Model Performance Metrics:\")\n",
    "print(f\"   â€¢ Mean Absolute Error (MAE): {mae:.2f}%\")\n",
    "print(f\"   â€¢ Root Mean Squared Error (RMSE): {rmse:.2f}%\")\n",
    "print(f\"   â€¢ RÂ² Score: {r2:.4f}\")\n",
    "\n",
    "# ============================================\n",
    "# 6. PREDICTION EXAMPLES\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PREDICTION EXAMPLES - SCENARIO ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "def predict_waste(category, event_type, shelf_life, stock_ordered, avg_daily_sales,\n",
    "                  price_per_unit, days_before_event, event_duration, needs_refrigeration,\n",
    "                  supplier_reliability, store_size, expected_sales):\n",
    "    \"\"\"\n",
    "    Predict waste percentage untuk skenario tertentu\n",
    "    \"\"\"\n",
    "    # Encode categorical\n",
    "    cat_encoded = le_category.transform([category])[0]\n",
    "    event_encoded = le_event.transform([event_type])[0]\n",
    "    \n",
    "    # Create feature array\n",
    "    features = np.array([[\n",
    "        cat_encoded, event_encoded, shelf_life, stock_ordered, avg_daily_sales,\n",
    "        price_per_unit, days_before_event, event_duration, needs_refrigeration,\n",
    "        supplier_reliability, store_size, expected_sales\n",
    "    ]])\n",
    "    \n",
    "    # Scale and predict\n",
    "    features_scaled = scaler.transform(features)\n",
    "    prediction = model.predict(features_scaled, verbose=0)[0][0]\n",
    "    \n",
    "    return max(0, prediction)  # Waste tidak bisa negatif\n",
    "\n",
    "# Scenario 1: Mudik Lebaran - Dairy Products\n",
    "print(\"\\nğŸ¯ SKENARIO 1: Stok Susu saat Mudik Lebaran\")\n",
    "print(\"-\" * 50)\n",
    "waste1 = predict_waste(\n",
    "    category='Dairy',\n",
    "    event_type='Mudik_Lebaran',\n",
    "    shelf_life=14,\n",
    "    stock_ordered=300,\n",
    "    avg_daily_sales=30,\n",
    "    price_per_unit=15,\n",
    "    days_before_event=7,\n",
    "    event_duration=12,\n",
    "    needs_refrigeration=1,\n",
    "    supplier_reliability=0.85,\n",
    "    store_size=2,\n",
    "    expected_sales=150\n",
    ")\n",
    "print(f\"   Kategori: Dairy (Susu)\")\n",
    "print(f\"   Event: Mudik Lebaran (12 hari)\")\n",
    "print(f\"   Stok dipesan: 300 unit\")\n",
    "print(f\"   Shelf life: 14 hari\")\n",
    "print(f\"   Expected sales: 150 unit\")\n",
    "print(f\"   ğŸ’¡ Prediksi Waste: {waste1:.2f}%\")\n",
    "print(f\"   ğŸ’° Potensi kerugian: Rp {(waste1/100 * 300 * 15):.0f}K\")\n",
    "\n",
    "# Scenario 2: Natal - Bakery\n",
    "print(\"\\nğŸ¯ SKENARIO 2: Stok Roti saat Natal\")\n",
    "print(\"-\" * 50)\n",
    "waste2 = predict_waste(\n",
    "    category='Bakery',\n",
    "    event_type='Natal_Tahun_Baru',\n",
    "    shelf_life=5,\n",
    "    stock_ordered=200,\n",
    "    avg_daily_sales=40,\n",
    "    price_per_unit=25,\n",
    "    days_before_event=3,\n",
    "    event_duration=8,\n",
    "    needs_refrigeration=0,\n",
    "    supplier_reliability=0.9,\n",
    "    store_size=2,\n",
    "    expected_sales=400\n",
    ")\n",
    "print(f\"   Kategori: Bakery (Roti)\")\n",
    "print(f\"   Event: Natal & Tahun Baru (8 hari)\")\n",
    "print(f\"   Stok dipesan: 200 unit\")\n",
    "print(f\"   Shelf life: 5 hari\")\n",
    "print(f\"   Expected sales: 400 unit\")\n",
    "print(f\"   ğŸ’¡ Prediksi Waste: {waste2:.2f}%\")\n",
    "print(f\"   ğŸ’° Potensi kerugian: Rp {(waste2/100 * 200 * 25):.0f}K\")\n",
    "\n",
    "# Scenario 3: Normal Day - Snacks\n",
    "print(\"\\nğŸ¯ SKENARIO 3: Stok Snack Hari Biasa\")\n",
    "print(\"-\" * 50)\n",
    "waste3 = predict_waste(\n",
    "    category='Snacks',\n",
    "    event_type='Normal',\n",
    "    shelf_life=120,\n",
    "    stock_ordered=100,\n",
    "    avg_daily_sales=15,\n",
    "    price_per_unit=10,\n",
    "    days_before_event=5,\n",
    "    event_duration=7,\n",
    "    needs_refrigeration=0,\n",
    "    supplier_reliability=0.95,\n",
    "    store_size=2,\n",
    "    expected_sales=105\n",
    ")\n",
    "print(f\"   Kategori: Snacks\")\n",
    "print(f\"   Event: Normal (7 hari)\")\n",
    "print(f\"   Stok dipesan: 100 unit\")\n",
    "print(f\"   Shelf life: 120 hari\")\n",
    "print(f\"   Expected sales: 105 unit\")\n",
    "print(f\"   ğŸ’¡ Prediksi Waste: {waste3:.2f}%\")\n",
    "print(f\"   ğŸ’° Potensi kerugian: Rp {(waste3/100 * 100 * 10):.0f}K\")\n",
    "\n",
    "# ============================================\n",
    "# 7. STOCK RECOMMENDATION SYSTEM\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STOCK RECOMMENDATION SYSTEM\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "def recommend_optimal_stock(category, event_type, shelf_life, avg_daily_sales,\n",
    "                            price_per_unit, days_before_event, event_duration,\n",
    "                            needs_refrigeration, supplier_reliability, store_size,\n",
    "                            target_waste_pct=5.0):\n",
    "    \"\"\"\n",
    "    Rekomendasikan jumlah stok optimal untuk meminimalkan waste\n",
    "    \"\"\"\n",
    "    # Estimasi expected sales berdasarkan event\n",
    "    event_multiplier = {\n",
    "        'Normal': 1.0,\n",
    "        'Mudik_Lebaran': 0.5,  # Sales turun saat mudik\n",
    "        'Natal_Tahun_Baru': 1.8,\n",
    "        'Long_Weekend': 1.4,\n",
    "        'Ramadan': 1.6\n",
    "    }\n",
    "    \n",
    "    expected_sales = int(avg_daily_sales * event_duration * event_multiplier.get(event_type, 1.0))\n",
    "    \n",
    "    # Binary search untuk optimal stock\n",
    "    low, high = expected_sales, expected_sales * 3\n",
    "    optimal_stock = expected_sales\n",
    "    \n",
    "    for stock in range(low, high, 10):\n",
    "        waste_pct = predict_waste(\n",
    "            category, event_type, shelf_life, stock, avg_daily_sales,\n",
    "            price_per_unit, days_before_event, event_duration, needs_refrigeration,\n",
    "            supplier_reliability, store_size, expected_sales\n",
    "        )\n",
    "        \n",
    "        if waste_pct <= target_waste_pct:\n",
    "            optimal_stock = stock\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return optimal_stock, expected_sales\n",
    "\n",
    "# Rekomendasi untuk Mudik Lebaran\n",
    "print(\"\\nğŸ“¦ REKOMENDASI STOK: Toko Retail saat Mudik Lebaran\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "products_to_stock = [\n",
    "    ('Dairy', 14, 30, 15, 1),\n",
    "    ('Bakery', 5, 25, 20, 0),\n",
    "    ('Meat', 5, 20, 50, 1),\n",
    "    ('Snacks', 90, 40, 10, 0),\n",
    "    ('Beverages', 60, 50, 8, 0),\n",
    "]\n",
    "\n",
    "print(f\"\\n{'Kategori':<12} {'Exp. Sales':<12} {'Optimal Stock':<15} {'Safety Buffer':<15}\")\n",
    "print(\"-\" * 54)\n",
    "\n",
    "for cat, shelf, daily_sales, price, refrig in products_to_stock:\n",
    "    opt_stock, exp_sales = recommend_optimal_stock(\n",
    "        category=cat,\n",
    "        event_type='Mudik_Lebaran',\n",
    "        shelf_life=shelf,\n",
    "        avg_daily_sales=daily_sales,\n",
    "        price_per_unit=price,\n",
    "        days_before_event=7,\n",
    "        event_duration=12,\n",
    "        needs_refrigeration=refrig,\n",
    "        supplier_reliability=0.85,\n",
    "        store_size=2,\n",
    "        target_waste_pct=5.0\n",
    "    )\n",
    "    buffer = ((opt_stock - exp_sales) / exp_sales * 100) if exp_sales > 0 else 0\n",
    "    print(f\"{cat:<12} {exp_sales:<12} {opt_stock:<15} {buffer:>6.1f}%\")\n",
    "\n",
    "# ============================================\n",
    "# 8. SUMMARY & INSIGHTS\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SUMMARY & BUSINESS INSIGHTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\"\"\n",
    "ğŸ“Š KEY FINDINGS:\n",
    "\n",
    "1. MUDIK LEBARAN adalah periode dengan waste tertinggi karena:\n",
    "   - Banyak konsumen pulang kampung\n",
    "   - Toko cenderung over-stock mengantisipasi lebaran\n",
    "   - Produk dairy & meat paling berisiko\n",
    "\n",
    "2. FAKTOR UTAMA PENYEBAB WASTE:\n",
    "   - Shelf life pendek + event duration panjang\n",
    "   - Over-ordering saat event besar\n",
    "   - Produk yang butuh refrigerasi\n",
    "\n",
    "3. REKOMENDASI UNTUK RETAIL:\n",
    "   âœ… Kurangi stok produk perishable 30-40% saat mudik\n",
    "   âœ… Fokus pada produk dengan shelf life > 30 hari\n",
    "   âœ… Tingkatkan stok produk tahan lama (snacks, beverages)\n",
    "   âœ… Koordinasi dengan supplier untuk delivery lebih sering\n",
    "   âœ… Implementasi dynamic pricing menjelang kadaluarsa\n",
    "\n",
    "4. POTENSI PENGHEMATAN:\n",
    "   Dengan prediksi akurat, retail dapat mengurangi food waste\n",
    "   hingga 20-35% dan menghemat kerugian signifikan.\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nâœ… Model berhasil dibuat dan siap digunakan untuk prediksi!\")\n",
    "print(\"=\" * 60)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
